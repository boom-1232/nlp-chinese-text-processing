{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 朴素贝叶斯文本分类器\n",
        "\n",
        "本项目实现了一个支持多种特征提取方法的朴素贝叶斯文本分类器，主要用于垃圾邮件检测。\n",
        "\n",
        "## 主要功能\n",
        "- 支持高频词特征和TF-IDF特征两种提取方式\n",
        "- 支持SMOTE样本平衡处理\n",
        "- 提供详细的模型评估指标\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import os\n",
        "import re\n",
        "import jieba\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"库导入成功！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, feature_method='freq', max_features=3000, use_smote=False):\n",
        "        \"\"\"\n",
        "        初始化朴素贝叶斯分类器\n",
        "        \n",
        "        Args:\n",
        "            feature_method (str): 特征提取方法，'freq'表示高频词，'tfidf'表示TF-IDF\n",
        "            max_features (int): 最大特征数量\n",
        "            use_smote (bool): 是否使用SMOTE进行样本平衡\n",
        "        \"\"\"\n",
        "        self.feature_method = feature_method\n",
        "        self.max_features = max_features\n",
        "        self.use_smote = use_smote\n",
        "        self.vocabulary = None\n",
        "        self.class_priors = {}\n",
        "        self.feature_probs = {}\n",
        "        self.tfidf_vectorizer = None\n",
        "        \n",
        "    def load_stopwords(self, stopwords_file='stopwords.txt'):\n",
        "        \"\"\"加载停用词\"\"\"\n",
        "        try:\n",
        "            with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
        "                stopwords = set(f.read().strip().split('\\n'))\n",
        "        except FileNotFoundError:\n",
        "            # 默认停用词列表\n",
        "            stopwords = {'的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '个', '上', '也', '很', '到', '要', '说', '来', '可以', '能', '会', '这', '那', '你', '他', '她'}\n",
        "        return stopwords\n",
        "    \n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"文本预处理\"\"\"\n",
        "        # 去除非中文字符\n",
        "        text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
        "        # 分词\n",
        "        words = jieba.cut(text)\n",
        "        # 去除停用词\n",
        "        stopwords = self.load_stopwords()\n",
        "        words = [word for word in words if word not in stopwords and len(word) > 1]\n",
        "        return words\n",
        "    \n",
        "    def extract_freq_features(self, texts):\n",
        "        \"\"\"提取高频词特征\"\"\"\n",
        "        all_words = []\n",
        "        processed_texts = []\n",
        "        \n",
        "        for text in texts:\n",
        "            words = self.preprocess_text(text)\n",
        "            processed_texts.append(words)\n",
        "            all_words.extend(words)\n",
        "        \n",
        "        # 统计词频，选择高频词\n",
        "        word_counts = Counter(all_words)\n",
        "        vocab = [word for word, count in word_counts.most_common(self.max_features)]\n",
        "        self.vocabulary = {word: idx for idx, word in enumerate(vocab)}\n",
        "        \n",
        "        # 构建特征矩阵\n",
        "        features = np.zeros((len(texts), len(vocab)))\n",
        "        for i, words in enumerate(processed_texts):\n",
        "            word_count = Counter(words)\n",
        "            for word, count in word_count.items():\n",
        "                if word in self.vocabulary:\n",
        "                    features[i, self.vocabulary[word]] = count\n",
        "        \n",
        "        return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    def extract_tfidf_features(self, texts):\n",
        "        \"\"\"提取TF-IDF特征\"\"\"\n",
        "        # 预处理文本\n",
        "        processed_texts = []\n",
        "        for text in texts:\n",
        "            words = self.preprocess_text(text)\n",
        "            processed_texts.append(' '.join(words))\n",
        "        \n",
        "        # 使用TfidfVectorizer\n",
        "        if self.tfidf_vectorizer is None:\n",
        "            self.tfidf_vectorizer = TfidfVectorizer(\n",
        "                max_features=self.max_features,\n",
        "                ngram_range=(1, 1),\n",
        "                min_df=1\n",
        "            )\n",
        "            features = self.tfidf_vectorizer.fit_transform(processed_texts).toarray()\n",
        "        else:\n",
        "            features = self.tfidf_vectorizer.transform(processed_texts).toarray()\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def extract_features(self, texts):\n",
        "        \"\"\"根据选择的方法提取特征\"\"\"\n",
        "        if self.feature_method == 'freq':\n",
        "            return self.extract_freq_features(texts)\n",
        "        elif self.feature_method == 'tfidf':\n",
        "            return self.extract_tfidf_features(texts)\n",
        "        else:\n",
        "            raise ValueError(\"feature_method must be 'freq' or 'tfidf'\")\n",
        "    \n",
        "    def train(self, X_text, y):\n",
        "        \"\"\"训练朴素贝叶斯分类器\"\"\"\n",
        "        # 提取特征\n",
        "        X = self.extract_features(X_text)\n",
        "        \n",
        "        # 如果使用SMOTE进行样本平衡\n",
        "        if self.use_smote and len(set(y)) > 1:\n",
        "            smote = SMOTE(random_state=42)\n",
        "            X, y = smote.fit_resample(X, y)\n",
        "            print(f\"SMOTE后样本分布: {Counter(y)}\")\n",
        "        \n",
        "        # 计算类先验概率\n",
        "        unique_classes = np.unique(y)\n",
        "        total_samples = len(y)\n",
        "        \n",
        "        for class_label in unique_classes:\n",
        "            class_count = np.sum(y == class_label)\n",
        "            self.class_priors[class_label] = class_count / total_samples\n",
        "        \n",
        "        # 计算特征概率\n",
        "        for class_label in unique_classes:\n",
        "            class_mask = (y == class_label)\n",
        "            class_features = X[class_mask]\n",
        "            \n",
        "            # 使用拉普拉斯平滑\n",
        "            feature_sums = np.sum(class_features, axis=0) + 1\n",
        "            total_features = np.sum(feature_sums)\n",
        "            \n",
        "            self.feature_probs[class_label] = feature_sums / total_features\n",
        "    \n",
        "    def predict(self, X_text):\n",
        "        \"\"\"预测\"\"\"\n",
        "        X = self.extract_features(X_text)\n",
        "        predictions = []\n",
        "        \n",
        "        for sample in X:\n",
        "            class_scores = {}\n",
        "            \n",
        "            for class_label in self.class_priors:\n",
        "                # 计算对数概率，避免下溢\n",
        "                log_prob = np.log(self.class_priors[class_label])\n",
        "                \n",
        "                # 计算特征概率\n",
        "                feature_probs = self.feature_probs[class_label]\n",
        "                \n",
        "                # 对于非零特征，计算概率\n",
        "                for i, feature_value in enumerate(sample):\n",
        "                    if feature_value > 0:\n",
        "                        log_prob += feature_value * np.log(feature_probs[i])\n",
        "                \n",
        "                class_scores[class_label] = log_prob\n",
        "            \n",
        "            # 选择概率最大的类别\n",
        "            predicted_class = max(class_scores, key=class_scores.get)\n",
        "            predictions.append(predicted_class)\n",
        "        \n",
        "        return np.array(predictions)\n",
        "\n",
        "# 将这部分添加到NaiveBayesClassifier类中\n",
        "print(\"NaiveBayesClassifier类方法补充完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_email_data(data_dir='emails'):\n",
        "    \"\"\"加载邮件数据\"\"\"\n",
        "    texts = []\n",
        "    labels = []\n",
        "    \n",
        "    # 加载垃圾邮件\n",
        "    spam_dir = os.path.join(data_dir, 'spam')\n",
        "    if os.path.exists(spam_dir):\n",
        "        for filename in os.listdir(spam_dir):\n",
        "            if filename.endswith('.txt'):\n",
        "                try:\n",
        "                    with open(os.path.join(spam_dir, filename), 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "                        texts.append(text)\n",
        "                        labels.append('spam')\n",
        "                except:\n",
        "                    continue\n",
        "    \n",
        "    # 加载正常邮件\n",
        "    ham_dir = os.path.join(data_dir, 'ham')\n",
        "    if os.path.exists(ham_dir):\n",
        "        for filename in os.listdir(ham_dir):\n",
        "            if filename.endswith('.txt'):\n",
        "                try:\n",
        "                    with open(os.path.join(ham_dir, filename), 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "                        texts.append(text)\n",
        "                        labels.append('ham')\n",
        "                except:\n",
        "                    continue\n",
        "    \n",
        "    # 如果没有找到邮件文件，创建示例数据\n",
        "    if not texts:\n",
        "        print(\"未找到邮件数据文件，使用示例数据...\")\n",
        "        texts = [\n",
        "            # 垃圾邮件示例\n",
        "            \"恭喜您中奖了！请点击链接领取奖金！马上行动吧！\",\n",
        "            \"免费获得iPhone最新款！立即注册！不要错过这个机会！\",\n",
        "            \"您的账户余额不足，请及时充值，否则将停机\",\n",
        "            \"紧急通知：您的密码即将过期，立即修改\",\n",
        "            \"限时优惠！买一送一！全场五折大酬宾！\",\n",
        "            \"代写毕业论文，硕博团队操作，保过查重！联系我们\",\n",
        "            \"【XX银行】账户被冻结！立即点击链接解冻\",\n",
        "            \"投资理财，月收益百分之三十，零风险高回报\",\n",
        "            \"独家内幕消息，股票必涨，赶紧买入\",\n",
        "            \"网络兼职，日赚三百，在家即可完成\",\n",
        "            \"美女主播在线聊天，点击进入房间\",\n",
        "            \"减肥神药，一周瘦十斤，无副作用\",\n",
        "            # 正常邮件示例\n",
        "            \"明天的会议改到下午3点，请各位同事准时参加\",\n",
        "            \"项目进度报告已发送到您的邮箱，请查收\",\n",
        "            \"请查收本周工作总结，有问题及时反馈\",\n",
        "            \"生日快乐！祝您身体健康，工作顺利！\",\n",
        "            \"感谢您的支持与配合，期待继续合作\",\n",
        "            \"会议记录已整理完毕，请查看附件\",\n",
        "            \"培训资料已上传至共享文件夹\",\n",
        "            \"月度绩效考核结果已公布，请查看\",\n",
        "            \"公司年会通知，时间地点详见附件\",\n",
        "            \"新员工入职手续办理指南\",\n",
        "            \"系统维护通知，请提前保存工作内容\",\n",
        "            \"客户满意度调查报告已完成\"\n",
        "        ]\n",
        "        labels = (['spam'] * 12) + (['ham'] * 12)\n",
        "    \n",
        "    return texts, labels\n",
        "\n",
        "\n",
        "def evaluate_model(classifier, X_test, y_test):\n",
        "    \"\"\"评估模型性能\"\"\"\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(\"模型评估结果\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # 准确率\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"准确率: {accuracy:.4f}\")\n",
        "    \n",
        "    # 详细分类报告\n",
        "    print(\"\\n分类报告:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))\n",
        "    \n",
        "    return accuracy, y_pred\n",
        "\n",
        "print(\"辅助函数定义完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载和预处理数据\n",
        "print(\"朴素贝叶斯文本分类器\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 加载数据\n",
        "texts, labels = load_email_data()\n",
        "print(f\"加载数据: {len(texts)} 条邮件\")\n",
        "print(f\"类别分布: {Counter(labels)}\")\n",
        "\n",
        "# 分割训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"训练集: {len(X_train)} 条\")\n",
        "print(f\"测试集: {len(X_test)} 条\")\n",
        "print(f\"训练集类别分布: {Counter(y_train)}\")\n",
        "print(f\"测试集类别分布: {Counter(y_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 高频词特征测试\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用高频词特征，不使用SMOTE\n",
        "print(\"\\n\" + \"=\"*20 + \" 高频词特征 \" + \"=\"*20)\n",
        "print(\"不使用SMOTE:\")\n",
        "\n",
        "classifier_freq = NaiveBayesClassifier(feature_method='freq', use_smote=False)\n",
        "classifier_freq.train(X_train, np.array(y_train))\n",
        "accuracy_freq, _ = evaluate_model(classifier_freq, X_test, np.array(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用高频词特征，使用SMOTE\n",
        "print(\"\\n使用SMOTE:\")\n",
        "\n",
        "classifier_freq_smote = NaiveBayesClassifier(feature_method='freq', use_smote=True)\n",
        "classifier_freq_smote.train(X_train, np.array(y_train))\n",
        "accuracy_freq_smote, _ = evaluate_model(classifier_freq_smote, X_test, np.array(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## TF-IDF特征测试\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用TF-IDF特征，不使用SMOTE\n",
        "print(\"\\n\" + \"=\"*20 + \" TF-IDF特征 \" + \"=\"*20)\n",
        "print(\"不使用SMOTE:\")\n",
        "\n",
        "classifier_tfidf = NaiveBayesClassifier(feature_method='tfidf', use_smote=False)\n",
        "classifier_tfidf.train(X_train, np.array(y_train))\n",
        "accuracy_tfidf, _ = evaluate_model(classifier_tfidf, X_test, np.array(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用TF-IDF特征，使用SMOTE\n",
        "print(\"\\n使用SMOTE:\")\n",
        "\n",
        "classifier_tfidf_smote = NaiveBayesClassifier(feature_method='tfidf', use_smote=True)\n",
        "classifier_tfidf_smote.train(X_train, np.array(y_train))\n",
        "accuracy_tfidf_smote, _ = evaluate_model(classifier_tfidf_smote, X_test, np.array(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 性能对比总结\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 总结结果\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"性能对比总结\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results = {\n",
        "    'freq_no_smote': accuracy_freq,\n",
        "    'freq_smote': accuracy_freq_smote,\n",
        "    'tfidf_no_smote': accuracy_tfidf,\n",
        "    'tfidf_smote': accuracy_tfidf_smote\n",
        "}\n",
        "\n",
        "for method, accuracy in results.items():\n",
        "    print(f\"{method}: {accuracy:.4f}\")\n",
        "    \n",
        "# 找出最佳模型\n",
        "best_method = max(results, key=results.get)\n",
        "best_accuracy = results[best_method]\n",
        "print(f\"\\n最佳模型: {best_method} (准确率: {best_accuracy:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 模型测试示例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用最佳模型进行预测示例\n",
        "test_texts = [\n",
        "    \"恭喜您中奖一百万！立即点击领取！\",\n",
        "    \"明天上午十点开会，请准时参加\",\n",
        "    \"免费赠送iPhone14！机会难得！\",\n",
        "    \"项目文档已经更新，请查收\"\n",
        "]\n",
        "\n",
        "print(\"模型预测示例:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 使用TF-IDF特征的模型进行预测\n",
        "predictions = classifier_tfidf.predict(test_texts)\n",
        "\n",
        "for text, pred in zip(test_texts, predictions):\n",
        "    print(f\"文本: {text}\")\n",
        "    print(f\"预测: {'垃圾邮件' if pred == 'spam' else '正常邮件'}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
