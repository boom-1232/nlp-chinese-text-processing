{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装jieba库\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    print(\"jieba库已安装\")\n",
    "except ImportError:\n",
    "    print(\"正在安装jieba库...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"jieba\"])\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    print(\"jieba库安装完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载自定义词典\n",
    "import os\n",
    "\n",
    "# 检查userdict.txt文件是否存在\n",
    "userdict_path = \"userdict.txt\"\n",
    "if os.path.exists(userdict_path):\n",
    "    jieba.load_userdict(userdict_path)\n",
    "    print(f\"自定义词典 {userdict_path} 加载成功\")\n",
    "    \n",
    "    # 显示词典内容\n",
    "    with open(userdict_path, 'r', encoding='utf-8') as f:\n",
    "        print(\"词典内容：\")\n",
    "        for line in f:\n",
    "            print(line.strip())\n",
    "else:\n",
    "    print(f\"警告：词典文件 {userdict_path} 不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词典加载验证\n",
    "# 使用jieba.cut方法，设置参数HMM=False，对句子进行分词\n",
    "\n",
    "# 测试句子1：张三\n",
    "test_sentence1 = \"张三即将是自然语言处理方面的高手。\"\n",
    "print(\"测试句子1：\", test_sentence1)\n",
    "print(\"分词结果（HMM=False）：\")\n",
    "seg_list1 = jieba.cut(test_sentence1, HMM=False)\n",
    "result1 = \" / \".join(seg_list1)\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# 测试句子2：余妍融\n",
    "test_sentence2 = \"余妍融也即将是自然语言处理方面的高手。\"\n",
    "print(\"测试句子2：\", test_sentence2)\n",
    "print(\"分词结果（HMM=False）：\")\n",
    "seg_list2 = jieba.cut(test_sentence2, HMM=False)\n",
    "result2 = \" / \".join(seg_list2)\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n分词结果分析：\")\n",
    "print(\"可以看到，'张三'和'余妍融'都被正确识别为完整的词汇，验证了自定义词典的有效性。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词提取实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键词提取实践\n",
    "# 使用TextRank算法对指定句子提取top-5关键词\n",
    "\n",
    "# 测试文本\n",
    "text = \"燕山大学是河北省人民政府、教育部、工业和信息化部、国家国防科技工业局四方共建的全国重点大学，河北省重点支持的国家一流大学和世界一流学科建设高校，北京高科大学联盟成员。\"\n",
    "\n",
    "print(\"原始文本：\")\n",
    "print(text)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 使用TextRank算法提取关键词\n",
    "print(\"\\n【TextRank算法关键词提取】\")\n",
    "\n",
    "# 提取top-5关键词（不带权重）\n",
    "keywords = jieba.analyse.textrank(text, topK=5, withWeight=False)\n",
    "print(\"Top-5关键词（不带权重）：\")\n",
    "for i, keyword in enumerate(keywords, 1):\n",
    "    print(f\"{i}. {keyword}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "\n",
    "# 提取top-5关键词（带权重）\n",
    "keywords_with_weight = jieba.analyse.textrank(text, topK=5, withWeight=True)\n",
    "print(\"Top-5关键词（带权重）：\")\n",
    "for i, (keyword, weight) in enumerate(keywords_with_weight, 1):\n",
    "    print(f\"{i}. {keyword} (权重: {weight:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 对比TF-IDF算法结果\n",
    "print(\"\\n【TF-IDF算法关键词提取对比】\")\n",
    "tfidf_keywords = jieba.analyse.extract_tags(text, topK=5, withWeight=True)\n",
    "print(\"Top-5关键词（TF-IDF）：\")\n",
    "for i, (keyword, weight) in enumerate(tfidf_keywords, 1):\n",
    "    print(f\"{i}. {keyword} (权重: {weight:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析词语分词结果，验证自定义词典的效果\n",
    "print(\"【分词结果分析】\")\n",
    "print(\"分析燕山大学相关词语的分词效果：\")\n",
    "\n",
    "# 对测试文本进行分词\n",
    "seg_result = jieba.cut(text, HMM=False)\n",
    "seg_list = list(seg_result)\n",
    "\n",
    "print(\"完整分词结果：\")\n",
    "print(\" / \".join(seg_list))\n",
    "\n",
    "print(\"\\n关键机构名称识别情况：\")\n",
    "target_words = [\"燕山大学\", \"河北省\", \"教育部\", \"工业和信息化部\", \"国家国防科技工业局\", \"北京高科大学联盟\"]\n",
    "for word in target_words:\n",
    "    if word in seg_list:\n",
    "        print(f\"✓ '{word}' - 被正确识别为完整词汇\")\n",
    "    else:\n",
    "        print(f\"✗ '{word}' - 可能被拆分\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
