# 中文分词与关键词提取实验

## 项目简介

本项目实现了中文分词和关键词提取的相关算法，包括基于词典的分词方法和基于jieba库的关键词提取功能。项目分为两个主要部分：词典分词算法实现和jieba库应用实践。

## 项目结构

```
.
├── README.md                          # 项目说明文档
├── userdict.txt                       # 自定义词典文件
├── dictionary_based_segmentation.ipynb # 任务一：基于词典的分词算法
└── main_jieba.ipynb                   # 任务三：jieba库应用与关键词提取
```

## 环境要求

- Python 3.6+
- Jupyter Notebook
- jieba库

## 安装依赖

```bash
pip install jieba jupyter
```

## 文件说明

### 1. userdict.txt - 自定义词典

自定义词典文件，用于jieba分词器的词汇扩展。格式为：

```
词语 频率 词性
```

包含的词汇类型：
- **人名**：张三、余妍融
- **专业术语**：自然语言处理
- **机构名称**：燕山大学、教育部、工业和信息化部等
- **学术概念**：全国重点大学、世界一流学科等

### 2. dictionary_based_segmentation.ipynb - 基于词典的分词算法

实现了三种经典的基于词典的中文分词算法：

#### 算法实现
- **正向最大匹配（Forward Maximum Matching, FMM）**
  - 从左到右扫描文本
  - 优先匹配最长词汇
  
- **逆向最大匹配（Backward Maximum Matching, BMM）**
  - 从右到左扫描文本
  - 优先匹配最长词汇
  
- **双向匹配（Bidirectional Matching）**
  - 结合正向和逆向匹配结果
  - 选择更优的分词方案

#### 评价标准
1. 词数少的结果优先
2. 单字词少的结果优先
3. 默认选择正向匹配结果

### 3. main_jieba.ipynb - jieba库应用与关键词提取

#### 第一章：自定义词典配置与加载验证

- **词典加载**：演示如何加载自定义词典
- **分词验证**：使用`jieba.cut(HMM=False)`验证自定义词典效果
- **测试用例**：验证人名"张三"、"余妍融"是否被正确识别

#### 第二章：关键词提取

- **TextRank算法原理**：详细介绍TextRank算法的理论基础
- **算法流程**：图构建、权重计算、迭代计算、排序输出
- **实践应用**：对燕山大学介绍文本提取top-5关键词
- **算法对比**：TextRank vs TF-IDF算法效果对比

## 使用方法

### 运行基于词典的分词算法

```bash
jupyter notebook dictionary_based_segmentation.ipynb
```

### 运行jieba分词与关键词提取

```bash
jupyter notebook main_jieba.ipynb
```

## 实验结果

### 分词效果验证

通过自定义词典成功实现：
- ✅ 人名"张三"、"余妍融"被正确识别为完整词汇
- ✅ 专业术语"自然语言处理"被正确切分
- ✅ 机构名称如"燕山大学"、"工业和信息化部"等被准确识别

### 关键词提取效果

使用TextRank算法对燕山大学介绍文本提取的关键词包括：
- 燕山大学
- 河北省  
- 教育部
- 全国重点大学
- 世界一流学科

## 技术特点

### 词典分词算法
- **高效性**：基于字典树的快速匹配
- **可控性**：完全基于词典，结果可预测
- **扩展性**：支持自定义词典扩展

### jieba关键词提取
- **TextRank算法**：基于图的无监督关键词提取
- **权重计算**：提供关键词重要性评分
- **多算法对比**：支持TextRank和TF-IDF算法对比

## 算法原理

### TextRank算法

TextRank是一种基于图排序的算法，其核心思想：

1. **图构建**：将词语构建为图的节点，词语共现关系为边
2. **权重计算**：根据词语共现频率计算边权重
3. **迭代计算**：通过迭代公式计算每个节点的重要性
4. **关键词排序**：按重要性得分排序输出关键词

### 双向匹配策略

双向匹配算法通过以下规则选择最优分词结果：
1. 优先选择词数较少的结果
2. 词数相同时选择单字词较少的结果  
3. 仍然相同时默认选择正向匹配结果

## 应用场景

- **文本预处理**：为NLP任务提供高质量的分词结果
- **信息检索**：提取文档关键词用于索引和检索
- **文本摘要**：基于关键词生成文本摘要
- **内容标签**：为文章自动生成标签

## 作者

本项目由自然语言处理课程学生完成，用于中文分词和关键词提取的学习与实践。

## 参考资料

- [jieba中文分词库](https://github.com/fxsjy/jieba)
- TextRank: Bringing Order into Texts (Mihalcea & Tarau, 2004)
- 《统计自然语言处理》宗成庆著 